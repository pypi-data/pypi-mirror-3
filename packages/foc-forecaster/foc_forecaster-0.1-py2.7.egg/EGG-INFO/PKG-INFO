Metadata-Version: 1.0
Name: foc-forecaster
Version: 0.1
Summary: UNKNOWN
Home-page: http://kermit.epska.org/
Author: Drazen Lucanin
Author-email: kermit666@gmail.com
License: UNKNOWN
Description: Installation
        =======
        
        Ubuntu Linux (or other Debian-based distro)
        -----------------------------------------------------------
        Open a terminal and change directory to the location of this file.
        
        Run the install_dependencies script:
        
        $ sh install_dependencies.sh
        
        Windows
        ------------
        Best to install the python(x,y) bundle (http://code.google.com/p/pythonxy/).
        
        Afterwards all the packages mentioned in the install_dependencies.sh file can be installed via pip. For example to install xlrd one would issue the following command inside Command Prompt:
        
        $ pip install xlrd
        
        Running
        =======
        Set the desired preferences in the configuration file:
        
        ./common/conf.py
        
        Write down the crisis/normal years in the XLS file:
        
        ./odabir_uzoraka.xls
        
        Position yourself inside the irb.foc.forecaster folder (pwd output just to show an example of the correct path):
        
        $ cd irb.foc.forecaster
        $ pwd
        /media/Data/Drazen/Dropbox/dev/eclipse/w2/irb.foc.forecaster
        
        Run the Python interpreter with the entry script run.py as an argument:
        
        $ python run.py
        
        
        Lay of the code
        ===============
        
        forcaster - main module, use it to start the program
        
        common
        ------
        |- conf - configuration file with all the preferences
        \- exceptions - all the custom exceptions are defined here
        
        model - contains the data structures
        -----
        |- country - code and list of indicators
        \- indicator - internal representation: list of dates, list of values
        
        sources - represents the data sources available online.
        -------
        \- wb - extracts data from the World Bank
        
        ai - classes regarding pattern recognition, train and test building etc.
        --
        |- input - parses XLS files to get crisis and normal period years
        |- output - writes the dataset into a text file in a subgroup-discovery-friendly format
        |- samples_set - the representation of the train and test datasets that can build samples based on the crisis/normal years input and indicators and countries specified in the conf file; fetches the data live from the World Bank API
        |- preprocessor - processes the samples to extract useful features (min, max, slope...)
        \- metadata - column labels and data type marks used when writing the dataset
        
        tests - unit tests for individual modules
        -----
        
Platform: UNKNOWN
