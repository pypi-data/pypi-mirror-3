[transmogrifier]
pipeline = 
	crawler
	cache
	typeguess
	drop
	template1
	template2
	template3
	template4
	templateauto
	sitemapper
	indexguess
	titleguess
	attachmentguess
	hideguess
	urltidy
	addfolders
	changetype
	ploneupload
	ploneupdate
	plonehide
	publish
	plonepublish
	plonealias
	ploneprune

[crawler]
blueprint = transmogrify.webcrawler
@doc = Crawls site or cache for content
@url = URL: the top url to crawl
@start-urls = LIST: additional urls to crawl at the start
@ignore = LIST: list of regex for urls to not crawl
@cache = DIR: local directory to read crawled items from instead of accessing the site directly
@patterns = LIST: Regular expressions to substitute before html is parsed. New line seperated
@subs = LIST: Text to replace each item in patterns. Must be the same number of lines as patterns
@maxsize = BYTES: don't crawl anything larger than this
@max = INT: Limit crawling to this number of pages
@ignore_robots = BOOL: Ignore robots.txt for when you really want their content
@debug = show extra debug information
url = 
ignore = 
	cgi-bin
	javascript:
cache = ${cache:output}
ignore_robots = false

[cache]
blueprint = transmogrify.webcrawler.cache
@doc = Saves content to disk
@output = DIR: relative directory to store cached downloads
@debug = show extra debug information
output = var/funnelwebcache/${crawler:url}/

[typeguess]
blueprint = transmogrify.webcrawler.typerecognitor
@doc = Sets Plone content type based on mime-type
@condition = TAL: Tal expression returning boolean called for each 'item'
@debug = show extra debug information

[drop]
blueprint = collective.transmogrifier.sections.condition
@doc = Useful to drop certain content
@condition = TAL: TAL expression returning boolean called for each 'item'
@debug = show extra debug information
condition = python:item.get('_mimetype') not in ['application/x-javascript','text/css','text/plain','application/x-java-byte-code'] and item.get('_path','').split('.')[-1] not in ['class']

[template1]
blueprint = transmogrify.htmlcontentextractor
@doc = Provide XPath for title, description, text etc.
	Specify rules like --template1:title="text //p[1]" --template1:text="html //p"
@debug = show extra debug information
@myfield = FORMAT XPATH: A rule to extract content from pages. XPATH must match a node
	unless FORMAT is "optional". FORMAT of "text" will strip html. FORMAT of "html"
	will return the matched html.

[template2]
blueprint = transmogrify.htmlcontentextractor
@doc = Used if no previous templates matched. see template1 for options

[template3]
blueprint = transmogrify.htmlcontentextractor
@doc = Used if no previous templates matched. see template1 for options

[template4]
blueprint = transmogrify.htmlcontentextractor
@doc = Used if no previous templates matched. see template1 for options

[templateauto]
blueprint = transmogrify.htmlcontentextractor.auto
@doc = Guesses XPaths of content by performing a cluster analysis of all the content not already matched
@condition = TAL: A TAL expression returning boolean called for each 'item'. Turned off by default.
@debug = show extra debug information
condition = python:False

[sitemapper]
blueprint = transmogrify.siteanalyser.sitemapper
@doc = Uses a indented html with links in to rearrange those links in the site
@condition = TAL: Which item to use as the sitemap
@debug = show extra debug information
condition = python: item.get('title','').lower().count("sitemap")

[indexguess]
blueprint = transmogrify.siteanalyser.defaultpage
@doc = Determines an item is a default page for a container if it has many links
	to items in that container even if not contained in that folder
@condition = TAL: tal expression returning boolean called for each 'item'
@debug = show extra debug information
@min_links = INT: If a page has this many links to a single folder's content it will be moved
@max_uplinks = INT: If a page has more than this many links parent folders then don't more it
condition = python:False
min_links = 2
max_uplinks = 2

[titleguess]
blueprint = transmogrify.siteanalyser.title
@doc = Tries to find better page titles by analysing backlink text
@condition = TAL: TAL expression returning boolean called for each 'item'
@debug = show extra debug information
@ignore = LIST: don't use backlink text containing these substrings
ignore = 
	click
	read more
	more info
	close
	Close
	http:
	file:
	img
	...
	. . .
condition = python:False

[attachmentguess]
blueprint = transmogrify.siteanalyser.attach
@doc = Finds items only referenced by one page and moves them into a new folder with the page as the default view
@condition = TAL: TAL expression returning boolean called for each 'item'
@debug = show extra debug information
@defaultpage = NAME: name to give created defaultpages
condition = python:False
defaultpage = index-html

[hideguess]
blueprint = transmogrify.siteanalyser.hidefromnav
@doc = Picks content which won't be shown in the site navigation
@condition = TAL: TAL expression to pick which items should be hidden
key = _exclude-from-navigation
condition = python:False

[urltidy]
blueprint = transmogrify.siteanalyser.urltidy
@doc = Applies title normalisation rules remove invalid chars from urls. It will also ensure all internal links are corrected
@debug = show extra debug information
@link_expr = TAL: TAL expression to set new value of the path
@use_title = TAL: TAL expression to switch id to use the title
link_expr = python:item['_path'].rsplit('.',1)[-1] in ['html','asp','php'] and item['_path'].rsplit('.',1)[0] or item['_path']
use_title = python:False

[addfolders]
blueprint = transmogrify.siteanalyser.pathsorter
@default_pages = LIST: names that indication page should be a defaultpage
@default_containers = TYPE: Type to set when creating folders
@debug = show extra debug information
default_pages = 
	index.html
	index
	index-html
	index.asp
	index.php
default_containers = Folder

[changetype]
blueprint = collective.transmogrifier.sections.inserter
@doc = Switch the type of the created object if desired
@value = TAL: TAL expression to give the new value for the Type of object.
key = string:_type
condition = python:item.get('_type')
value = python:item['_type']

[ploneupload]
blueprint = transmogrify.ploneremote.remoteconstructor
@doc = Adds content to plone via xmlrpc
@target = URL: The base url for where all content should be created. Can support basic authentication
	e.g. target = http://admin:admin@localhost:8080/Plone
@debug = show extra debug information
target = 
type-key = _type
path-key = _path

[ploneupdate]
blueprint = transmogrify.ploneremote.remoteschemaupdater
@doc = Updates content of existing object on a remote plone site via xmlrpc
@target = URL: the base url for where all content should be updated. Can support basic authentication
@debug = show extra debug information
target = ${ploneupload:target}
type-key = _type
path-key = _path

[plonehide]
blueprint = transmogrify.ploneremote.remotenavigationexcluder
@doc = Hide items from the navigation
	(hints to which items should be hidden are set earlier in pipeline)
	by default it will hide items not linked to outside of any body text
@debug = show extra debug information
target = ${ploneupload:target}
type-key = _type
path-key = _path
exclude-from-navigation-key = ${hideguess:key}

[publish]
blueprint = collective.transmogrifier.sections.inserter
@doc = Set the workflow transition
@value = TAL: TAL expression to return the transition to workflow
key = string:_transitions
value = python:["publish"]
condition = python:item.get('_type') != 'Image' and not options.get('disabled')

[plonepublish]
blueprint = transmogrify.ploneremote.remoteworkflowupdater
@doc = Publish or otherwise change the workflow state of remote plone content
@debug = show extra debug information
transitions = submit publish
transitions-key = _transitions
target = ${ploneupload:target}
type-key = _type
path-key = _path

[plonealias]
blueprint = transmogrify.ploneremote.remoteredirector
@doc = Creates aliases for items that have moved
target = ${ploneupload:target}
type-key = _type
path-key = _path

[ploneprune]
blueprint = transmogrify.ploneremote.remoteprune
@doc = Delete objects which are on the remote site, but not in local copy
@condition = TAL: TAL expression for which folders to remove old content
target = ${ploneupload:target}
condition = python:item.get('_type') in ['Folder']

[localupload]
blueprint = transmogrify.webcrawler.cache
@doc = Save transformed site locally
@output = DIR: directory to load transformed content into for debugging
output = 
@debug = show extra debug information

