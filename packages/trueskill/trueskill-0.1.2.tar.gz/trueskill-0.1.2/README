
                           // TrueSkill //

                    A Bayesian Skill Rating System


 What's TrueSkill?
===================
    
  TrueSkill(TM) is a rating system among game players. It has been
  used on Xbox Live to rank and match players. TrueSkill system
  quantizes "TRUE" skill points by a Bayesian inference algorithm.

  More information is available at http://bit.ly/moserware-trueskill
  and http://research.microsoft.com/en-us/projects/trueskill/

  This project is a Python package which implements TrueSkill system.


 Tutorial
==========

= Measure Player's Skill

  Let's suppose that our sample game is 2:1. `Rating` objects mean
  each game players' skill points:

    >>> from trueskill import Rating
    >>> r1, r2, r3 = Rating(), Rating(), Rating()
    >>> team1 = (r1, r2)
    >>> team2 = (r3,)

  TrueSkill system uses Gaussian distribution as player's skill point.
  The initial mu(mean) of rating is 25 and the initial sigma(standard
  deviation) is 25/3 = 8.333...

    >>> [team1, team2]
    [(
      Rating(mu=25.000, sigma=8.333),
      Rating(mu=25.000, sigma=8.333)
    ), (
      Rating(mu=25.000, sigma=8.333)
    )]

  The first team has won the game. See the below transformation of the
  ratings:

    >>> from trueskill import transform_ratings
    >>> transform_ratings([team1, team2])
    [(
      Rating(mu=25.604, sigma=8.075),
      Rating(mu=25.604, sigma=8.075)
    ), (
      Rating(mu=24.396, sigma=8.075)
    )]

  The mu values in the first team transform from 25 to 25.6 and in the
  second team transform from 25 to 24.4. The ratings were transformed
  just a little. But, how does it work if the second team player has
  beaten 2 players in the first team, by himself?

    >>> transform_ratings([team1, team2], ranks=[1, 0]) # reversed ranks
    [(
      Rating(mu=16.269, sigma=7.317),
      Rating(mu=16.269, sigma=7.317)
    ), (
      Rating(mu=33.731, sigma=7.317)
    )]

  In the first team, 25 to 16.3 and in the second team 25 to 33.7. Now
  we have large transformations because it is a surprising result that
  1 player beats 2 players.

  It is just a simplest example. TrueSkill can estimate accurate
  skills in this way. We only need enough game results!

= Match Quality

  We also can calculate the fairness of any games with `match_quality`
  function:

    >>> from trueskill import match_quality
    >>> match_quality([team1, team2])
    0.1346981464530322

  The result shows that the probability of a draw game is 13.47%.
  Let's see another result of a really fair game:

    >>> match_quality([(Rating(25, 0.001),), (Rating(25, 0.001),)])
    0.9999999712000012

  A much exact skill point follows very low sigma value such as the
  above ratings (sigma=0.001). Very low sigma value indicates that
  the rating is much more precise. Also, because of the same ratings,
  TrueSkill assures a draw of this game, a super-fair game.

  This feature would help you implement a fair match making system.

= Make Players Be Happy

  A skill point is a measure of player's real ability. Someday, this
  value will be convergent to the value that's exactly we are finding.
  But the value can be a less than the initial value (mu=25). To
  prevent players from despairing by knowing their own rating directly,
  we need to deceive our players into growing up in general.
  
  Okay, enough for the reason but how? Just use `Rating.exposure`
  property:

    >>> Rating().exposure
    0.0
    >>> Rating(mu=24, sigma=7).exposure # mu -= 1
    2.9999999999999964
    >>> Rating(mu=22, sigma=6).exposure # mu -= 2
    4.0
    >>> Rating(mu=26, sigma=5).exposure # mu += 4
    11.0

  An exposure value starts from 0 instead of 25. It can decrease
  sometimes but the growth graph will go up on the whole.


 How to get?
=============

  Install with "pip" command:

    $ pip install trueskill

  or check out development version:

    $ git clone git://github.com/sublee/trueskill.git


 Author
========

  I'm Heungsub Lee <h@subl.ee>, a game server developer. Any regarding
  questions or patches are welcomed.
