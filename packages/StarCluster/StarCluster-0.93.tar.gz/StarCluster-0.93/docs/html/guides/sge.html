
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Sun Grid Engine (SGE) QuickStart &mdash; StarCluster v0.93 documentation</title>
    <link rel="stylesheet" href="../_static/pylons.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.93',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="StarCluster v0.93 documentation" href="../index.html" />
    <link rel="up" title="StarCluster Guides" href="index.html" />
    <link rel="next" title="Plugin Documentation" href="../plugins/index.html" />
    <link rel="prev" title="StarCluster Guides" href="index.html" />
<link rel="stylesheet" href="../_static/nobile.css" type="text/css" media="screen" charset="utf-8" />
<link rel="stylesheet" href="../_static/neuton.css" type="text/css" media="screen" charset="utf-8" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="../_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->
<link rel="shortcut icon" href="../_static/starcluster.ico"/>

  </head>
  <body>
<div class="header-small">
	
	<div class="logo-small">
		<a href="../index.html">
      		<img class="logo" src="../_static/logo-small.png" alt="Logo"/>
		</a>
  	</div>
</div>

    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../plugins/index.html" title="Plugin Documentation"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="StarCluster Guides"
             accesskey="P">previous</a> |</li>
    	<li><a href="../index.html">Home</a> &raquo;</li>
          <li><a href="../contents.html" >Master Table of Contents</a> &raquo;</li>
          <li><a href="index.html" accesskey="U">StarCluster Guides</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="sun-grid-engine-sge-quickstart">
<h1>Sun Grid Engine (SGE) QuickStart<a class="headerlink" href="#sun-grid-engine-sge-quickstart" title="Permalink to this headline">¶</a></h1>
<p>The Sun Grid Engine queuing system is useful when you have a lot of tasks to
execute and want to distribute the tasks over a cluster of machines. For
example, you might need to run hundreds of simulations/experiments with varying
parameters or need to convert 300 videos from one format to another. Using a
queuing system in these situations has the following advantages:</p>
<ul class="simple">
<li><strong>Scheduling</strong> - allows you to schedule a virtually unlimited amount of work
to be performed when resources become available. This means you can simply
submit as many tasks (or <em>jobs</em>) as you like and let the queuing system
handle executing them all.</li>
<li><strong>Load Balancing</strong> - automatically distributes tasks across the cluster such
that any one node doesn&#8217;t get overloaded compared to the rest.</li>
<li><strong>Monitoring/Accounting</strong> - ability to monitor all submitted jobs and query
which cluster nodes they&#8217;re running on, whether they&#8217;re finished, encountered
an error, etc. Also allows querying job history to see which tasks were
executed on a given date, by a given user, etc.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Of course, just because a queuing system is installed doesn&#8217;t mean you
<em>have</em> to use it at all. You can run your tasks across the cluster in any
way you see fit and the queuing system should not interfere.  However, you
will most likely end up needing to implement the above features in some
fashion in order to optimally utilize the cluster.</p>
</div>
<div class="section" id="submitting-jobs">
<h2>Submitting Jobs<a class="headerlink" href="#submitting-jobs" title="Permalink to this headline">¶</a></h2>
<p>A job in SGE represents a task to be performed on a node in the cluster and
contains the command line used to start the task. A job may have specific
resource requirements but in general should be agnostic to <em>which</em> node in the
cluster it runs on as long as its resource requirements are met.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">All jobs require <em>at least</em> one available slot on a node in the cluster to
run.</p>
</div>
<p>Submitting jobs is done using the <em>qsub</em> command. Let&#8217;s try submitting a simple
job that runs the <em>hostname</em> command on a given cluster node:</p>
<div class="highlight-python"><pre>sgeadmin@master:~$ qsub -V -b y -cwd hostname
Your job 1 ("hostname") has been submitted</pre>
</div>
<ul class="simple">
<li>The <strong>-V</strong> option to <em>qsub</em> states that the job should have the same
environment variables as the shell executing <em>qsub</em> (<em>recommended</em>)</li>
<li>The <strong>-b</strong> option to <em>qsub</em> states that the command being executed could be a
single binary executable or a bash script. In this case the command
<em>hostname</em> is a single binary. This option takes a <em>y</em> or <em>n</em> argument
indicating either <em>yes</em> the command is a binary or <em>no</em> it is not a binary.</li>
<li>The <strong>-cwd</strong> option to <em>qsub</em> tells Sun Grid Engine that the job should be
executed in the same directory that <em>qsub</em> was called.</li>
<li>The last argument to <em>qsub</em> is the command to be executed (<em>hostname</em> in this
case)</li>
</ul>
<p>Notice that the <em>qsub</em> command, when successful, will print the job number to
stdout. You can use the job number to monitor the job&#8217;s status and progress
within the queue as we&#8217;ll see in the next section.</p>
</div>
<div class="section" id="monitoring-jobs-in-the-queue">
<h2>Monitoring Jobs in the Queue<a class="headerlink" href="#monitoring-jobs-in-the-queue" title="Permalink to this headline">¶</a></h2>
<p>Now that our job has been submitted, let&#8217;s take a look at the job&#8217;s status in
the queue using the command <em>qstat</em>:</p>
<div class="highlight-python"><pre>sgeadmin@master:~$ qstat
job-ID prior name user state submit/start at queue slots ja-task-ID
-------------------------------------------------------------------
1 0.00000 hostname sgeadmin qw 09/09/2009 14:58:00 1
sgeadmin@master:~$</pre>
</div>
<p>From this output, we can see that the job is in the <strong>qw</strong> state which stands
for <em>queued and waiting</em>. After a few seconds, the job will transition into a
<strong>r</strong>, or <em>running</em>, state at which point the job will begin executing:</p>
<div class="highlight-python"><pre>sgeadmin@master:~$ qstat
job-ID  prior   name       user         state submit/start at     queue  slots ja-task-ID
-----------------------------------------------------------------------------------------
1 0.00000 hostname   sgeadmin     r     09/09/2009 14:58:14                1
sgeadmin@master:~$</pre>
</div>
<p>Once the job has finished, the job will be removed from the queue and will no
longer appear in the output of <em>qstat</em>:</p>
<div class="highlight-python"><pre>sgeadmin@master:~$ qstat
sgeadmin@master:~$</pre>
</div>
<p>Now that the job has finished let&#8217;s move on to the next section to see how we
view a job&#8217;s output.</p>
</div>
<div class="section" id="viewing-a-job-s-output">
<h2>Viewing a Job&#8217;s Output<a class="headerlink" href="#viewing-a-job-s-output" title="Permalink to this headline">¶</a></h2>
<p>Sun Grid Engine creates stdout and stderr files in the job&#8217;s working directory
for each job executed. If any additional files are created during a job&#8217;s
execution, they will also be located in the job&#8217;s working directory unless
explicitly saved elsewhere.</p>
<p>The job&#8217;s stdout and stderr files are named after the job with the extension
ending in the job&#8217;s number.</p>
<p>For the simple job submitted above we have:</p>
<div class="highlight-python"><pre>sgeadmin@master:~$ ls hostname.*
hostname.e1 hostname.o1
sgeadmin@master:~$ cat hostname.o1
node001
sgeadmin@master:~$ cat hostname.e1
sgeadmin@master:~$</pre>
</div>
<p>Notice that Sun Grid Engine automatically named the job <em>hostname</em> and created
two output files: hostname.e1 and hostname.o1. The <strong>e</strong> stands for stderr and
the <strong>o</strong> for stdout. The <strong>1</strong> at the end of the files&#8217; extension is the job
number. So if the job had been named <em>my_new_job</em> and was job #23 submitted,
the output files would look like:</p>
<div class="highlight-python"><pre>my_new_job.e23 my_new_job.o23</pre>
</div>
</div>
<div class="section" id="monitoring-cluster-usage">
<h2>Monitoring Cluster Usage<a class="headerlink" href="#monitoring-cluster-usage" title="Permalink to this headline">¶</a></h2>
<p>After a while you may be curious to view the load on Sun Grid Engine. To do
this, we use the <em>qhost</em> command:</p>
<div class="highlight-python"><pre>sgeadmin@master:~$ qhost
HOSTNAME ARCH NCPU LOAD MEMTOT MEMUSE SWAPTO SWAPUS
-------------------------------------------------------------------------------
global - - - - - - -
master lx24-x86 1 0.00 1.7G 62.7M 896.0M 0.0
node001 lx24-x86 1 0.00 1.7G 47.8M 896.0M 0.0</pre>
</div>
<p>The output shows the architecture (<strong>ARCH</strong>), number of cpus (<strong>NCPU</strong>), the
current load (<strong>LOAD</strong>), total memory (<strong>MEMTOT</strong>), and currently used memory
(<strong>MEMUSE</strong>) and swap space (<strong>SWAPTO</strong>) for each node.</p>
<p>You can also view the average load (load_avg) per node using the &#8216;-f&#8217; option to
<em>qstat</em>:</p>
<div class="highlight-python"><pre>sgeadmin@master:~$ qstat -f
queuename qtype resv/used/tot. load_avg arch states
---------------------------------------------------------------------------------
all.q@master.c BIP 0/0/1 0.00 lx24-x86
---------------------------------------------------------------------------------
all.q@node001.c BIP 0/0/1 0.00 lx24-x86</pre>
</div>
</div>
<div class="section" id="creating-a-job-script">
<h2>Creating a Job Script<a class="headerlink" href="#creating-a-job-script" title="Permalink to this headline">¶</a></h2>
<p>In the &#8216;Submitting a Job&#8217; section we submitted a single command <em>hostname</em>.
This is useful for simple jobs but for more complex jobs where we need to
incorporate some logic we can use a so-called <em>job script</em>. A <em>job script</em> is
essentially a bash script that contains some logic and executes any number of
external programs/scripts:</p>
<div class="highlight-python"><pre>#!/bin/bash
echo "hello from job script!"
echo "the date is" `date`
echo "here's /etc/hosts contents:"
cat /etc/hosts
echo "finishing job :D"</pre>
</div>
<p>As you can see, this script simply executes a few commands (such as echo, date,
cat, etc.) and exits. Anything printed to the screen will be put in the job&#8217;s
stdout file by Sun Grid Engine.</p>
<p>Since this is just a bash script, you can put any form of logic necessary in
the job script (i.e. if statements, while loops, for loops, etc.) and you may
call any number of external programs needed to complete the job.</p>
<p>Let&#8217;s see how you run this new job script. Save the script above to
/home/sgeadmin/jobscript.sh on your StarCluster and execute the following as
the sgeadmin user:</p>
<div class="highlight-python"><pre>sgeadmin@master:~$ qsub -V jobscript.sh
Your job 6 ("jobscript.sh") has been submitted</pre>
</div>
<p>Now that the job has been submitted, let&#8217;s call <em>qstat</em> periodically until the
job has finished since this job should only take a second to run once it&#8217;s
executed:</p>
<div class="highlight-python"><pre>sgeadmin@master:~$ qstat
job-ID prior name user state submit/start at queue slots ja-task-ID
-------------------------------------------------------------------
6 0.00000 jobscript. sgeadmin qw 09/09/2009 16:18:43 1

sgeadmin@master:~$ qstat
job-ID prior name user state submit/start at queue slots ja-task-ID
-------------------------------------------------------------------
6 0.00000 jobscript. sgeadmin qw 09/09/2009 16:18:43 1

sgeadmin@master:~$ qstat
job-ID prior name user state submit/start at queue slots ja-task-ID
-------------------------------------------------------------------
6 0.00000 jobscript. sgeadmin qw 09/09/2009 16:18:43 1

sgeadmin@master:~$ qstat
job-ID prior name user state submit/start at queue slots ja-task-ID
-------------------------------------------------------------------
6 0.00000 jobscript. sgeadmin qw 09/09/2009 16:18:43 1

sgeadmin@master:~$ qstat
job-ID prior name user state submit/start at queue slots ja-task-ID
-------------------------------------------------------------------
6 0.55500 jobscript. sgeadmin r 09/09/2009 16:18:57 all.q@node001.c 1

sgeadmin@master:~$ qstat
sgeadmin@master:~$</pre>
</div>
<p>Now that the job is finished, let&#8217;s take a look at the output files:</p>
<div class="highlight-python"><pre>sgeadmin@master:~$ ls jobscript.sh*
jobscript.sh jobscript.sh.e6 jobscript.sh.o6
sgeadmin@master:~$ cat jobscript.sh.o6
hello from job script!
the date is Wed Sep 9 16:18:57 UTC 2009
here's /etc/hosts contents:
# Do not remove the following line or programs that require network functionality will fail
127.0.0.1 localhost.localdomain localhost
10.252.167.143 master
10.252.165.173 node001
finishing job :D
sgeadmin@master:~$ cat jobscript.sh.e6
sgeadmin@master:~$</pre>
</div>
<p>We see from looking at the output that the stdout file contains the output of
the echo, date, and cat statements in the job script and that the stderr file
is blank meaning there were no errors during the job&#8217;s execution. Had something
failed, such as a command not found error for example, these errors would have
appeared in the stderr file.</p>
</div>
<div class="section" id="deleting-a-job-from-the-queue">
<h2>Deleting a Job from the Queue<a class="headerlink" href="#deleting-a-job-from-the-queue" title="Permalink to this headline">¶</a></h2>
<p>What if a job is stuck in the queue, is taking too long to run, or was simply
started with incorrect parameters? You can delete a job from the queue using
the <em>qdel</em> command in Sun Grid Engine. Below we launch a simple &#8216;sleep&#8217; job
that sleeps for 10 seconds so that we can kill it using <em>qdel</em>:</p>
<div class="highlight-python"><pre>sgeadmin@master:~$ qsub -b y -cwd sleep 10
Your job 3 ("sleep") has been submitted
sgeadmin@master:~$ qdel 3
sgeadmin has registered the job 3 for deletion</pre>
</div>
<p>After running <em>qdel</em> you&#8217;ll notice the job is gone from the queue:</p>
<div class="highlight-python"><pre>sgeadmin@master:~$ qstat
sgeadmin@master:~$</pre>
</div>
</div>
<div class="section" id="openmpi-and-sun-grid-engine">
<h2>OpenMPI and Sun Grid Engine<a class="headerlink" href="#openmpi-and-sun-grid-engine" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">OpenMPI must be compiled with SGE support (&#8211;with-sge) to make use of the
tight-integration between OpenMPI and SGE as documented in this section.
This is the case on all of StarCluster&#8217;s public AMIs.</p>
</div>
<p>OpenMPI supports tight integration with Sun Grid Engine. This integration
allows Sun Grid Engine to handle assigning hosts to parallel jobs and to
properly account for parallel jobs.</p>
<div class="section" id="openmpi-parallel-environment">
<h3>OpenMPI Parallel Environment<a class="headerlink" href="#openmpi-parallel-environment" title="Permalink to this headline">¶</a></h3>
<p>StarCluster by default sets up a parallel environment, called &#8220;orte&#8221;, that has
been configured for OpenMPI integration within SGE and has a number of <em>slots</em>
equal to the total number of processors in the cluster.  You can inspect the
SGE parallel environment by running:</p>
<div class="highlight-python"><pre>sgeadmin@ip-10-194-13-219:~$ qconf -sp orte
pe_name            orte
slots              16
user_lists         NONE
xuser_lists        NONE
start_proc_args    /bin/true
stop_proc_args     /bin/true
allocation_rule    $round_robin
control_slaves     TRUE
job_is_first_task  FALSE
urgency_slots      min
accounting_summary FALSE</pre>
</div>
<p>This is the default configuration for a two-node, c1.xlarge cluster (16 virtual
cores).</p>
</div>
<div class="section" id="round-robin-vs-fill-up-modes">
<h3>Round Robin vs Fill Up Modes<a class="headerlink" href="#round-robin-vs-fill-up-modes" title="Permalink to this headline">¶</a></h3>
<p>Notice the <em>allocation_rule</em> setting in the output of the <em>qconf</em> command in
the previous section. This defines how to assign <em>slots</em> to a job. By default
StarCluster configures <em>round_robin</em> allocation.  This means that if a job
requests 8 <em>slots</em> for example, it will go to the first machine, grab a single
slot if available, move to the next machine and grab a single slot if
available, and so on wrapping around the cluster again if necessary to allocate
8 <em>slots</em> to the job.</p>
<p>You can also configure the parallel environment to try and localize <em>slots</em> as
much as possible using the <em>fill_up</em> allocation rule. With this rule, if a user
requests 8 <em>slots</em> and a single machine has 8 <em>slots</em> available, that job will
run entirely on one machine. If 5 <em>slots</em> are available on one host and 3 on
another, it will take all 5 on that host, and all 3 on the other host. In other
words, this rule will greedily take all <em>slots</em> on a given node until the slot
requirement for the job is met.</p>
<p>You can switch between <em>round_robin</em> and <em>fill_up</em> modes using the following
command:</p>
<div class="highlight-python"><pre>$ qconf -mp orte</pre>
</div>
<p>This will open up vi (or any editor defined in <em>EDITOR</em> env variable) and let
you edit the parallel environment settings. To change from <em>round_robin</em> to
<em>fill_up</em> in the above example, change the <em>allocation_rule</em> line from:</p>
<div class="highlight-python"><pre>allocation_rule    $round_robin</pre>
</div>
<p>to:</p>
<div class="highlight-python"><pre>allocation_rule    $fill_up</pre>
</div>
<p>After making the change and saving the file you can verify your settings using:</p>
<div class="highlight-python"><pre>sgeadmin@ip-10-194-13-219:~$ qconf -sp orte
pe_name            orte
slots              16
user_lists         NONE
xuser_lists        NONE
start_proc_args    /bin/true
stop_proc_args     /bin/true
allocation_rule    $fill_up
control_slaves     TRUE
job_is_first_task  FALSE
urgency_slots      min
accounting_summary FALSE</pre>
</div>
</div>
<div class="section" id="submitting-openmpi-jobs-using-a-parallel-environment">
<h3>Submitting OpenMPI Jobs using a Parallel Environment<a class="headerlink" href="#submitting-openmpi-jobs-using-a-parallel-environment" title="Permalink to this headline">¶</a></h3>
<p>The general workflow for running MPI code is:</p>
<ol class="arabic simple">
<li>Compile the code using mpicc, mpicxx, mpif77, mpif90, etc.</li>
<li>Copy the resulting executable to the same path on all nodes or to an
NFS-shared location on the master node</li>
</ol>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">It is important that the path to the executable is <em>identical</em> on all nodes
for mpirun to correctly launch your parallel code. The easiest approach is
to copy the executable somewhere under /home on the master node since /home
is NFS-shared across all nodes in the cluster.</p>
</div>
<ol class="arabic" start="3">
<li><p class="first">Run the code on <em>X</em> number of machines using:</p>
<div class="highlight-python"><pre>$ mpirun -np X -hostfile myhostfile ./mpi-executable arg1 arg2 [...]</pre>
</div>
</li>
</ol>
<p>where the hostfile looks something like:</p>
<div class="highlight-python"><pre>$ cat /path/to/hostfile
master  slots=2
node001 slots=2
node002 slots=2
node003 slots=2</pre>
</div>
<p>However, when using an SGE parallel environment with OpenMPI <strong>you no longer
have to specify the -np, -hostfile, -host, etc. options to mpirun</strong>. This is
because SGE will <em>automatically</em> assign hosts and processors to be used by
OpenMPI for your job. You also do not need to pass the &#8211;byslot and &#8211;bynode
options to mpirun given that these mechanisms are now handled by the <em>fill_up</em>
and <em>round_robin</em> modes specified in the SGE parallel environment.</p>
<p>Instead of using the above formulation create a simple job script that contains
a very simplified mpirun call:</p>
<div class="highlight-python"><pre>$ cat myjobscript.sh
mpirun /path/to/mpi-executable arg1 arg2 [...]</pre>
</div>
<p>Then submit the job using the <em>qsub</em> command and the <em>orte</em> parallel
environment automatically configured for you by StarCluster:</p>
<div class="highlight-python"><pre>$ qsub -pe orte 24 ./myjobscript.sh</pre>
</div>
<p>The <strong>-pe</strong> option species which parallel environment to use and how many
<em>slots</em> to request. The above example requests 24 <em>slots</em> (or processors) using
the <em>orte</em> parallel environment. The parallel environment automatically takes
care of distributing the MPI job amongst the SGE nodes using the
<em>allocation_rule</em> defined in the environment&#8217;s settings.</p>
<p>You can also do this without a job script like so:</p>
<div class="highlight-python"><pre>$ cd /path/to/executable
$ qsub -b y -cwd -pe orte 24 mpirun ./mpi-executable arg1 arg2 [...]</pre>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Sun Grid Engine (SGE) QuickStart</a><ul>
<li><a class="reference internal" href="#submitting-jobs">Submitting Jobs</a></li>
<li><a class="reference internal" href="#monitoring-jobs-in-the-queue">Monitoring Jobs in the Queue</a></li>
<li><a class="reference internal" href="#viewing-a-job-s-output">Viewing a Job&#8217;s Output</a></li>
<li><a class="reference internal" href="#monitoring-cluster-usage">Monitoring Cluster Usage</a></li>
<li><a class="reference internal" href="#creating-a-job-script">Creating a Job Script</a></li>
<li><a class="reference internal" href="#deleting-a-job-from-the-queue">Deleting a Job from the Queue</a></li>
<li><a class="reference internal" href="#openmpi-and-sun-grid-engine">OpenMPI and Sun Grid Engine</a><ul>
<li><a class="reference internal" href="#openmpi-parallel-environment">OpenMPI Parallel Environment</a></li>
<li><a class="reference internal" href="#round-robin-vs-fill-up-modes">Round Robin vs Fill Up Modes</a></li>
<li><a class="reference internal" href="#submitting-openmpi-jobs-using-a-parallel-environment">Submitting OpenMPI Jobs using a Parallel Environment</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter">StarCluster Guides</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../plugins/index.html"
                        title="next chapter">Plugin Documentation</a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" size="18" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../plugins/index.html" title="Plugin Documentation"
             >next</a> |</li>
        <li class="right" >
          <a href="index.html" title="StarCluster Guides"
             >previous</a> |</li>
    	<li><a href="../index.html">Home</a> &raquo;</li>
          <li><a href="../contents.html" >Master Table of Contents</a> &raquo;</li>
          <li><a href="index.html" >StarCluster Guides</a> &raquo;</li> 
      </ul>
    </div>


    <div class="footer">
        &copy; Copyright 2011, Software Tools for Academics and Researchers.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.0.7.
    </div>


<script type="text/javascript">
//<![CDATA[
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    //]]>
    </script><script type="text/javascript">
//<![CDATA[
    try{
        var pageTracker = _gat._getTracker("UA-1048253-12");
        pageTracker._trackPageview();
    } catch(err) {}
    //]]>
    </script>

  </body>
</html>